import os
import json
import gradio as gr
import requests
import random
import numpy as np
import threading
import erniebot
import websocket
from dashscope.audio.tts_v2 import *
import tempfile
import time
import cv2

import dashscope
from dotenv import find_dotenv, load_dotenv
from utils.format_html import format_welcome_html, format_story_html2, format_introduce_html
from utils.ernie_bot_client import chat_completion
from utils.bots import QuestionAnswerBot, ProblemSetBot
from utils.video_generation import generate_gradient_video
from utils.speech_client import tts_damo_api, asr_damo_api, convert_pcm_to_float

_ = load_dotenv(find_dotenv())

erniebot.api_type = os.environ["api_type"]
erniebot.access_token = os.environ["access_token"]

uid = threading.current_thread().name
dashscope.api_key = "sk-b9924d51b1c14e338cc7136d5520b893"
model = "cosyvoice-v1"
voice = "longxiaochun"

host_avatar = 'assets/host_image.png'
user_avatar = 'assets/user_image.png'
url = "https://api.siliconflow.cn/v1/stabilityai/stable-diffusion-3-medium/text-to-image"
os.makedirs('temp', exist_ok=True)
# ä½¿ç”¨ gr.State æ¥å­˜å‚¨ä¸»é¢˜é€‰æ‹©
global_topic_value = gr.State(None)


def init_game(state):
    state['question_bot'] = QuestionAnswerBot(topic, bot_name="question_answering_bot")
    return state


def update_global_topic(new_value):
    global_topic_value.value = new_value


def transfer_text(input_text):
    return input_text  # ç›´æ¥è¿”å›è¾“å…¥çš„æ–‡æœ¬


def download_image(url, save_dir):
    response = requests.get(url)
    if response.status_code == 200:
        img_name = url.split("/")[-1]
        img_path = os.path.join(save_dir, img_name)
        with open(img_path, 'wb') as f:
            f.write(response.content)
        return img_path
    else:
        return None


def generate_images(story_content):
    image_urls = image_submit_click(story_content)
    save_dir = "temp_images"
    os.makedirs(save_dir, exist_ok=True)

    image_paths = []
    for url in image_urls:
        if url != "No URL found in the response.":
            img_path = download_image(url, save_dir)
            if img_path:
                image_paths.append(img_path)

            else:
                image_paths.append(None)
        else:
            image_paths.append(None)


    return tuple(image_paths)


def story_submit_click(text_story_title, choices):  # å®šä¹‰æ•…äº‹æäº¤æŒ‰é’®ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
    if text_story_title.strip() == '':  # å¦‚æœæ•…äº‹æ ‡é¢˜ä¸ºç©º
        return 'ä½ æƒ³å¬ä»€ä¹ˆæ•…äº‹å‘¢ï¼Ÿä¸çŸ¥é“æ€ä¹ˆå†™ï¼Ÿçœ‹çœ‹å³è¾¹å¤§å®¶éƒ½åœ¨å…³æ³¨å•¥'  # è¿”å›æç¤ºä¿¡æ¯
    prompt = f"""ä½ æ˜¯ä¸€ä½{choices}æ–¹é¢çš„åšå£«,"""
    prompt += """æ“…é•¿ç”¨é£è¶£å¹½é»˜çš„æ–¹å¼ç»™å°æœ‹å‹è®²æ•…äº‹ï¼Œæ ¹æ®ç»™ä½ çš„æ ‡é¢˜ï¼š{}ï¼Œç¼–å†™ä¸€ä¸ªå°æ•…äº‹
                è¦æ±‚ï¼š
                1.ç›´æ¥è¾“å‡ºæ•…äº‹å†…å®¹;
                2.æ•…äº‹è¦æœ‰é€»è¾‘æ€§ï¼Œæ•…äº‹å†…å®¹æœ‰è¶£ï¼Œè‡³å°‘åˆ†4ä¸ªå…·ä½“åœºæ™¯;
                3.å­—æ•°ä¿æŒåœ¨200å­—å·¦å³ï¼Œä¸”è¦æœ‰è¶£å‘³æ€§ã€‚
            """
    response = chat_completion(prompt.format(text_story_title))  # è°ƒç”¨å¯¹è¯å®Œæˆå‡½æ•°ï¼Œç”Ÿæˆæ•…äº‹å†…å®¹
    return response  # è¿”å›ç”Ÿæˆçš„æ•…äº‹å†…å®¹


def story_more_click(choice):  # å®šä¹‰è·å–æ›´å¤šç¤ºä¾‹æŒ‰é’®ç‚¹å‡»äº‹ä»¶å¤„ç†å‡½æ•°
    # update_global_topic(global_topic_value)
    # print("111")
    prompt = f"""æˆ‘æƒ³ç»™å°æœ‹å‹æ™®åŠæœ‰å…³{choice}çš„çŸ¥è¯†ï¼Œéœ€è¦é€šè¿‡ä¸€ä¸ªæ•…äº‹æ¥å¼•å…¥ï¼Œå¸®æˆ‘æƒ³ä¸€ä¸ªåªæœ‰"ä¸€å¥è¯"çš„æ•…äº‹ä¸»é¢˜æŒ‰ç…§ä¸‹é¢ç»™å‡ºçš„ã€æ ¼å¼ã€‘ã€‚
                è¦æ±‚ï¼š
                1.åªéœ€è¦è¿”è¿˜ä¸€ä¸ª"ä¸€å¥è¯"çš„å°±å¯ä»¥;
                2.å­—æ•°æ§åˆ¶åœ¨25å­—å·¦å³;
                3.å†…å®¹è¦æœ‰è¶£å‘³æ€§ï¼Œæœ‰åé—®ï¼Œèƒ½å¤Ÿå¸å¼•å°æœ‹å‹;
                4.ã€æ ¼å¼ã€‘:"ä¸€å¥è¯"
            """
    response1 = chat_completion(prompt)
    prompt += "æ•…äº‹ä¸»é¢˜è¦å®Œå…¨ä¸ä¸€æ ·"
    response2 = chat_completion(prompt)
    prompt += "æ•…äº‹ä¸»é¢˜è¦å®Œå…¨ä¸ä¸€æ ·"
    response3 = chat_completion(prompt)
    return response1, response2, response3


def ques_gen_click(state, value):
    prompt = f"""ä½ ç°åœ¨æ˜¯ä¸€ä¸ªå¯¹è¿™ä¸ªä¸–ç•Œå……æ»¡å¥½å¥‡çš„å°æœ‹å‹ï¼Œæœ‰å¾ˆå¤šçš„é—®é¢˜åœ¨ä½ çš„è„‘æµ·ä¸­ï¼Œ
                    ä½ æƒ³çŸ¥é“çš„é—®é¢˜æ˜¯å…³äº{value}çš„
                    è¦æ±‚ï¼š
                    1.åªéœ€è¦10ä¸ªå­—å·¦å³ã€‚
                    2.é—®é¢˜éå¸¸çš„æœ‰è¶£å‘³æ€§ï¼Œå’Œå¯æ¢ç´¢æ€§ã€‚
                """
    response1 = chat_completion(prompt)
    response2 = chat_completion(prompt)
    response3 = chat_completion(prompt)
    return (response1, response2, response3)


def ques_button_click(question_text):
    return question_text


def send_button_click(user_chat_input, state, chatbot):
    chatbot.append((user_chat_input, None))
    yield (chatbot, '')
    bot = state['question_bot']
    response = bot.get_response(user_chat_input)
    # print(response)
    state['answer_story'] = response
    # print(state['answer_story'])
    chatbot.append((None, response))
    yield (chatbot, '')


def tts_speech_synthesis(text, out_path="output.wav", max_retries=3):
    for attempt in range(max_retries):
        try:
            synthesizer = SpeechSynthesizer(model=model, voice=voice)
            audio = synthesizer.call(text)
            # print(audio)
            with open(out_path, 'wb') as f:
                f.write(audio)
                print(f"Audio saved to {out_path}")
            save_audio_file(audio, "temp/audio_story.wav")
            return out_path
        except websocket._exceptions.WebSocketConnectionClosedException as e:
            if attempt < max_retries - 1:
                print(
                    f"WebSocket connection closed. Retrying attempt {attempt + 1}/{max_retries}...")
                time.sleep(1)  # Wait before retrying
            else:
                raise e  # If retries exhausted, raise the exception


def save_audio_file(audio_data, file_path):
    with open(file_path, "wb") as audio_file:
        audio_file.write(audio_data)


def update_audio_content():
    text = text_story_content.value
    if text.strip():
        audio_file = tts_speech_synthesis(text)
        # print(audio_file)
        save_audio_file(audio_file, "temp/audio_story.wav")
        audio_story_content.value = open(audio_file, "rb").read()

    # ä¿®æ”¹æ–‡ç”Ÿå›¾API


def image_submit_click(text_story_content):
    # æ ¼å¼åŒ–æç¤ºä¿¡æ¯
    prompt = ("ä½ æ˜¯ä¸€ä½è¯­è¨€å¤§å¸ˆï¼Œç²¾é€šä¸­æ–‡å’Œè‹±æ–‡ï¼Œæ“…é•¿æ ¹æ®ä¸­æ–‡æ•…äº‹å†…å®¹ï¼Œæ‹†è§£å¹¶æ€»ç»“å‡ºæ•…äº‹çš„ä¸»è¦æƒ…èŠ‚ï¼Œå¹¶ç”¨4å¥è¯è‹±æ–‡æ¥æè¿°ã€‚\n"
              "æ•…äº‹å†…å®¹ï¼š{}\n"
              "è¦æ±‚ï¼š\n"
              "1.è¾“å‡º4å¥å®Œæ•´è‹±æ–‡çš„åœºæ™¯æè¿°å³å¯ï¼Œä¼˜ç¾ï¼Œé€‚åˆå„¿ç«¥è§‚çœ‹ç†è§£ã€‚\n"
              "2.æ¯å¥è¯éƒ½è¦ç®€çŸ­ï¼Œ15ä¸ªå•è¯å·¦å³ã€‚\n"
              "3.æ¯å¥è¯ä¹‹é—´æ¢è¡Œåˆ†éš”ã€‚")

    # è·å–åœºæ™¯æè¿°
    response = chat_completion(prompt.format(text_story_content))

    # å°†è¿”å›çš„æè¿°æŒ‰è¡Œåˆ†å‰²ï¼Œå¾—åˆ°å››å¥åœºæ™¯æè¿°
    lines = response.split('\n')

    # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘å››å¥æè¿°
    if len(lines) < 4:
        # å¦‚æœä¸è¶³å››å¥ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²è¡¥é½
        lines += [""] * (4 - len(lines))

    # åˆ†åˆ«å­˜å‚¨æ¯å¥æè¿°åˆ°ä¸åŒçš„å˜é‡
    response1, response2, response3, response4 = lines[0], lines[1], lines[2], lines[3]

    # ç”Ÿæˆå›¾åƒ
    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "authorization": "Bearer sk-kqlavbqxkdeucapczvzjafeqoonaevxidspwenypcrjyflfb"
    }

    payloads = [{
        "prompt": response1,
        "image_size": "1024x1024",
        "batch_size": 1,
        "num_inference_steps": 20,
        "guidance_scale": 7.5
    }, {
        "prompt": response2,
        "image_size": "1024x1024",
        "batch_size": 1,
        "num_inference_steps": 20,
        "guidance_scale": 7.5
    }, {
        "prompt": response3,
        "image_size": "1024x1024",
        "batch_size": 1,
        "num_inference_steps": 20,
        "guidance_scale": 7.5
    }, {
        "prompt": response4,
        "image_size": "1024x1024",
        "batch_size": 1,
        "num_inference_steps": 20,
        "guidance_scale": 7.5
    }]

    image_urls = []

    for payload in payloads:
        response = requests.post(url, json=payload, headers=headers)
        response_data = json.loads(response.text)
        urls = response_data.get("images", [])

        if urls:
            image_urls.append(urls[0].get("url"))
        else:
            image_urls.append("No URL found in the response.")

    return (image_urls[0], image_urls[1], image_urls[2], image_urls[3])


def generate_keywords_click(state):
    messages = state['question_bot'].messages
    if len(messages) == 0:
        return 'ä»Šå¤©è¿˜æ²¡æœ‰èŠå¤©å“¦ï¼Œå¿«å»æ¨¡å—äºŒå’Œæœºå™¨äººæ¢ç´¢æœªçŸ¥ä¸–ç•Œå§ï¼'
    contents = [mes['content'] for mes in messages if mes['role'] == 'assistant']
    if 'answer_story' in state:
        # print(state['answer_story'])
        contents.append(state['answer_story'])
    content = '\n'.join(contents)
    prompt = f"""æ ¹æ®æ‰€ç»™çš„æ–‡æœ¬å†…å®¹ï¼Œæå–2-3ä¸ªæœ‰å…³{global_topic_value.value}çš„å…³é”®å­—ã€‚"""
    prompt += """å†…å®¹ï¼š{}
                è¦æ±‚ï¼š
                1.åªéœ€è¦è¾“å‡º2-3ä¸ªå…³é”®è¯å³å¯ã€‚
                2.å…³é”®è¯ä¹‹é—´ç”¨æ¢è¡Œç¬¦éš”å¼€ã€‚
                3.ç›´æ¥è¾“å‡ºå…³é”®è¯
            """
    keywords = chat_completion(prompt.format(content))
    return keywords


def generate_problem_click(keywords_text, state):
    keywords = keywords_text.split('\n')
    keywords = [word.strip() for word in keywords if len(word.strip()) > 0]
    if len(keywords) == 0:
        keywords = []
    keyword = random.choice(keywords)
    # print(str(global_topic_value.value))
    problemset.generate_problem(keyword, global_topic_value.value)
    question = "## " + problemset.question
    options = ["A." + problemset.choices[0], "B." + problemset.choices[1],
               "C." + problemset.choices[2], "D." + problemset.choices[3]]
    radio = gr.Radio(options, label="é€‰æ‹©ä½ è®¤ä¸ºæ­£ç¡®çš„ä¸€é¡¹")
    state['answer_submit'] = False
    return (question, radio, problemset.subject, problemset.difficulty, problemset.analysis)


def answer_submit_click(choices_radio, state):
    response = problemset.checkAnswer(choices_radio)
    state['answer_submit'] = True
    return response


def save_problem_click(state):
    if 'answer_submit' in state and state['answer_submit']:
        question_df = problemset.save_question()
        return question_df
    else:
        return []


def save_record_click():
    file_name = problemset.save_xlsx()
    return file_name


def clear_record_click():
    question_df = problemset.clear_xlsx()
    return question_df


def main_ui(state, topic):
    state['topic'] = topic
    global global_topic_value
    global_topic_value.value = topic
    return {welcome_tab: gr.update(visible=False), main_tab: gr.update(visible=True)}


def welcome_ui(state, topic):
    state['topic'] = topic
    return {welcome_tab: gr.update(visible=True), main_tab: gr.update(visible=False)}


def tts_speech_synthesis1(text, max_retries=3):
    for attempt in range(max_retries):
        try:
            synthesizer = SpeechSynthesizer(model=model, voice=voice)
            answer = text[-1][-1]
            audio2 = synthesizer.call(answer)
            save_audio_file(audio2, "temp/audio_story.wav")
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                f.write(audio2)
                return f.name
        except websocket._exceptions.WebSocketConnectionClosedException as e:
            if attempt < max_retries - 1:
                print(
                    f"WebSocket connection closed. Retrying attempt {attempt + 1}/{max_retries}...")
                time.sleep(1)  # Wait before retrying
            else:
                raise e  # If retries exhausted, raise the exception


def update_audio_content1():
    text = user_chatbot.value
    if text.strip():
        audio_file = tts_speech_synthesis(text)
        answer_audio.value = open(audio_file, "rb").read()


def generate_images1(story_content, state):
    image_urls = answer_image_gen_click(story_content)
    save_dir = "temp_images"
    os.makedirs(save_dir, exist_ok=True)

    image_paths = []
    for url in image_urls:
        if url != "No URL found in the response.":
            img_path = download_image(url, save_dir)
            print(img_path)
            if img_path:
                image_paths.append(img_path)
            else:
                image_paths.append(None)
        else:
            image_paths.append(None)
    print(image_paths)
    print(state)
    state['answer_images'] = image_paths  # å°†å›¾ç‰‡è·¯å¾„å­˜å‚¨åˆ° state ä¸­
    print(state['answer_images'])

    return tuple(image_paths)


def answer_video_gen_click(state):
    answer_story = state['answer_story']
    print(answer_story)
    audio_path = tts_speech_synthesis(answer_story, out_path='temp/audio_story.wav')
    image_files = state['answer_images']
    print(image_files)
    output_path = generate_gradient_video(image_files, audio_path, output_path='temp/video_story.mp4')
    return output_path

def answer_image_gen_click(chatbot):
    text_story_content = chatbot[-1][-1]
    # æ ¼å¼åŒ–æç¤ºä¿¡æ¯
    prompt = ("ä½ æ˜¯ä¸€ä½è¯­è¨€å¤§å¸ˆï¼Œç²¾é€šä¸­æ–‡å’Œè‹±æ–‡ï¼Œæ“…é•¿æ ¹æ®ä¸­æ–‡æ•…äº‹å†…å®¹ï¼Œæ‹†è§£å¹¶æ€»ç»“å‡ºæ•…äº‹çš„ä¸»è¦æƒ…èŠ‚ï¼Œå¹¶ç”¨4å¥è¯è‹±æ–‡æ¥æè¿°ã€‚\n"
              "æ•…äº‹å†…å®¹ï¼š{}\n"
              "è¦æ±‚ï¼š\n"
              "1.è¾“å‡º4å¥å®Œæ•´è‹±æ–‡çš„åœºæ™¯æè¿°å³å¯ï¼Œä¼˜ç¾ï¼Œé€‚åˆå„¿ç«¥è§‚çœ‹ç†è§£ã€‚\n"
              "2.æ¯å¥è¯éƒ½è¦ç®€çŸ­ï¼Œ15ä¸ªå•è¯å·¦å³ã€‚\n"
              "3.æ¯å¥è¯ä¹‹é—´æ¢è¡Œåˆ†éš”ã€‚")

    # è·å–åœºæ™¯æè¿°
    response = chat_completion(prompt.format(text_story_content))

    # å°†è¿”å›çš„æè¿°æŒ‰è¡Œåˆ†å‰²ï¼Œå¾—åˆ°å››å¥åœºæ™¯æè¿°
    lines = response.split('\n')

    # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘å››å¥æè¿°
    if len(lines) < 2:
        # å¦‚æœä¸è¶³å››å¥ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²è¡¥é½
        lines += [""] * (2 - len(lines))

    # åˆ†åˆ«å­˜å‚¨æ¯å¥æè¿°åˆ°ä¸åŒçš„å˜é‡
    text1, text2 = lines[0], lines[1]

    # ç”Ÿæˆå›¾åƒ
    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "authorization": "Bearer sk-kqlavbqxkdeucapczvzjafeqoonaevxidspwenypcrjyflfb"
    }

    payloads = [{
        "prompt": text1,
        "image_size": "1024x1024",
        "batch_size": 1,
        "num_inference_steps": 20,
        "guidance_scale": 7.5
    }, {
        "prompt": text2,
        "image_size": "1024x1024",
        "batch_size": 1,
        "num_inference_steps": 20,
        "guidance_scale": 7.5
    }]

    image_urls = []

    for payload in payloads:
        response = requests.post(url, json=payload, headers=headers)
        response_data = json.loads(response.text)
        urls = response_data.get("images", [])
        if urls:
            image_urls.append(urls[0].get("url"))
        else:
            image_urls.append("No URL found in the response.")

    return (image_urls[0], image_urls[1])


# åˆ›å»º Gradio ç•Œé¢
theme = gr.Theme.load('assets/theme.json')
with gr.Blocks(css="assets/app.css", theme=theme) as demo:
    state = gr.State({'session_seed': uid})
    demo.load(init_game, inputs=[state], outputs=[state])
    warning_html_code = """
        <div class="hint" style="background-color: rgba(255, 255, 0, 0.15); padding: 10px; margin: 10px 0; border-radius: 5px; border: 1px solid #ffcc00;">
            <p>\N{fire} Powered by <a href="https://github.com/PaddlePaddle/ERNIE-Bot-SDK/">ErnieBot and ErnieBot Agent</a>\N{fire}</p>
        </div>
        """
    gr.HTML(warning_html_code)
    welcome_tab = gr.Tab('æ¸¸æˆä»‹ç»')
    with welcome_tab:
        user_chat_bot_cover = gr.HTML(format_welcome_html())
        with gr.Row():
            topic = gr.Dropdown(
                choices=["å¤©æ–‡ä¸»é¢˜", "åŠ¨ç‰©ä¸»é¢˜", "å¤ç”Ÿç‰©ä¸»é¢˜", "æµ·æ´‹ä¸»é¢˜", "ç”Ÿå‘½ä¸»é¢˜", "æ¤ç‰©ä¸»é¢˜", "èˆªç©ºä¸»é¢˜"],
                # åˆ›å»ºä¸‹æ‹‰èœå•é€‰æ‹©ä¸»é¢˜
                value=None,
                label="ğŸ“– æ¢ç´¢ä¸»é¢˜",
                interactive=True,
                allow_custom_value=True)
            start_button = gr.Button(value='ğŸš€ç™»é™†æ˜ŸçƒğŸš€', variant='primary')

    main_tab = gr.Tab('åº”ç”¨ä¸»ç•Œé¢', visible=False)
    with main_tab:
        with gr.Row():
            with gr.Column():
                gr.HTML(format_story_html2())
                with gr.Tabs() as tabs:
                    # å¼€å§‹ç¬¬1ä¸ªæ¨¡å—
                    story_tab = gr.Tab(label="ç¡å‰å°æ•…äº‹", id=1)
                    with story_tab:
                        with gr.Row():
                            with gr.Column():
                                text_story_title = gr.Textbox(lines=5, label='ä¸€å¥è¯ç”Ÿæˆæ•…äº‹')
                                story_submit = gr.Button("å¼€å§‹æ•…äº‹åˆ›ä½œ", variant='primary')
                                with gr.Row():
                                    audio_submit = gr.Button("ç”Ÿæˆè¯­éŸ³", variant='primary')
                                    image_submit = gr.Button("ç”Ÿæˆå‰§ç…§", variant='primary')
                            with gr.Column():
                                with gr.Accordion("ä¸çŸ¥é“æ€ä¹ˆå†™ï¼Ÿçœ‹çœ‹å¤§å®¶éƒ½åœ¨å…³æ³¨å•¥", open=True):
                                    with gr.Row():
                                        text_more_story_title1 = gr.Textbox(placeholder='é—®é¢˜1', lines=1, label='é—®é¢˜',
                                                                            scale=5, show_label=False)
                                        choose_story1 = gr.Button("é‡‡çº³", scale=1, variant='primary', min_width=1)
                                    with gr.Row():
                                        text_more_story_title2 = gr.Textbox(placeholder='é—®é¢˜2', lines=1, label='é—®é¢˜',
                                                                            scale=5, show_label=False)
                                        choose_story2 = gr.Button("é‡‡çº³", scale=1, variant='primary', min_width=1)
                                    with gr.Row():
                                        text_more_story_title3 = gr.Textbox(placeholder='é—®é¢˜3', lines=1,
                                                                            show_label=False, label='é—®é¢˜', scale=5)
                                        choose_story3 = gr.Button("é‡‡çº³", scale=1, variant='primary', min_width=1)

                                    story_more = gr.Button("æ•…äº‹ä¸»é¢˜")
                        with gr.Row():
                            with gr.Column(scale=1):
                                text_story_content = gr.Textbox(lines=6, label='æ•…äº‹å†…å®¹')
                            with gr.Column(scale=1):
                                audio_story_content = gr.Audio(label="æ•…äº‹éŸ³é¢‘", autoplay=True)
                        with gr.Row():
                            image0 = gr.Image(label="ç…§ç‰‡1",
                                              type="filepath",  # è¾“å‡ºç±»å‹ä¹Ÿæ˜¯å›¾åƒ
                                              )
                            image1 = gr.Image(label="ç…§ç‰‡2",
                                              type="filepath",  # è¾“å‡ºç±»å‹ä¹Ÿæ˜¯å›¾åƒ
                                              )
                            image2 = gr.Image(label="ç…§ç‰‡3",
                                              type="filepath",  # è¾“å‡ºç±»å‹ä¹Ÿæ˜¯å›¾åƒ
                                              )
                            image3 = gr.Image(label="ç…§ç‰‡4",
                                              type="filepath",  # è¾“å‡ºç±»å‹ä¹Ÿæ˜¯å›¾åƒ
                                              )


                    # å¼€å§‹ç¬¬2ä¸ªæ¨¡å—
                    question_tab = gr.Tab(label="å¥½å¥‡ä¸‰åƒé—®", id=2)
                    with question_tab:
                        with gr.Row():
                            with gr.Column(scale=1):
                                user_chatbot = gr.Chatbot(
                                    value=[[None,
                                            'æ¬¢è¿æ¥åˆ° å¿«ä¹æ˜Ÿçƒ-å¥½å¥‡ä¸‰åƒé—®ï¼Œåˆšåˆšçš„æ•…äº‹è¿˜è¿‡ç˜¾å—ï¼Œå¿«æ¥å’Œæˆ‘æ¢ç´¢æ›´å¤šæœªçŸ¥ä¸–ç•Œå§ï¼']],
                                    elem_classes="app-chatbot",
                                    avatar_images=[host_avatar, user_avatar],
                                    label="é—®ç­”æ¢ç´¢åŒº",
                                    show_label=True,
                                    bubble_full_width=False, )
                            with gr.Column(scale=1):
                                with gr.Accordion("ä¸çŸ¥é“æ€ä¹ˆæé—®ï¼Ÿè®©AIå¼•å¯¼ä½ å§", open=True):
                                    with gr.Row():
                                        with gr.Column(scale=3):
                                            ques_text_1 = gr.Textbox(label='é—®é¢˜1', show_label=False,
                                                                     placeholder='é—®é¢˜1')
                                        with gr.Column(min_width=70, scale=1):
                                            ques_button_1 = gr.Button("é‡‡çº³", )
                                    with gr.Row():
                                        with gr.Column(scale=3):
                                            ques_text_2 = gr.Textbox(label='é—®é¢˜2', show_label=False,
                                                                     placeholder='é—®é¢˜2')
                                        with gr.Column(min_width=70, scale=1):
                                            ques_button_2 = gr.Button("é‡‡çº³")
                                    with gr.Row():
                                        with gr.Column(scale=3):
                                            ques_text_3 = gr.Textbox(label='é—®é¢˜3', show_label=False,
                                                                     placeholder='é—®é¢˜3')
                                        with gr.Column(min_width=70, scale=1):
                                            ques_button_3 = gr.Button("é‡‡çº³")
                                ques_gen_button = gr.Button("å¸®æˆ‘ç”Ÿæˆé—®é¢˜", variant='primary')
                                with gr.Row():
                                    with gr.Column():
                                        user_chat_input = gr.Textbox(
                                            label='é—®é¢˜è¾“å…¥åŒº',
                                            placeholder='ä½ æƒ³é—®æˆ‘ç‚¹ä»€ä¹ˆå‘¢ï¼Ÿ',
                                            show_label=True,
                                            lines=4)
                                with gr.Column():
                                    send_button = gr.Button('ğŸ“£æé—®ğŸ“£', variant='primary', min_width=0)
                        with gr.Row():
                            answer_audio_gen_button = gr.Button("ç”ŸæˆéŸ³é¢‘", variant='primary')
                            answer_image_gen_button = gr.Button("ç”Ÿæˆç…§ç‰‡", variant='primary')
                            answer_video_gen_button = gr.Button("ç”Ÿæˆè§†é¢‘", variant='primary')
                            # answer_video_gen_button = gr.Button("ç”Ÿæˆè§†é¢‘", variant='primary')
                        with gr.Row():
                            answer_audio = gr.Audio(label="éŸ³é¢‘å›ç­”", interactive=False, autoplay=True)  # åˆ›å»ºéŸ³é¢‘æ’­æ”¾å™¨ç»„ä»¶
                            answer_image0 = gr.Image(label="ç…§ç‰‡1")  # åˆ›å»ºå›¾ç‰‡å±•ç¤ºç»„ä»¶ï¼Œç”¨äºæ˜¾ç¤ºå‰§ç…§0
                            answer_image1 = gr.Image(label="ç…§ç‰‡2")  # åˆ›å»ºå›¾ç‰‡å±•ç¤ºç»„ä»¶ï¼Œç”¨äºæ˜¾ç¤ºå‰§ç…§1
                            answer_video = gr.Video(label="æ•…äº‹è§£è¯´", interactive=False,
                                                    autoplay=True)  # åˆ›å»ºè§†é¢‘æ’­æ”¾å™¨ç»„ä»¶ï¼Œç”¨äºæ’­æ”¾æ•…äº‹è§£è¯´

                    # å¼€å§‹ç¬¬3ä¸ªæ¨¡å—
                    game_tab = gr.Tab(label="çŸ¥è¯†å¤§æŒ‘æˆ˜", id=3)
                    with game_tab:
                        problemset = ProblemSetBot(global_topic_value)
                        with gr.Row():
                            with gr.Column():
                                with gr.Tab("AIå‡ºé¢˜åŒº"):
                                    keywords_text = gr.Textbox(label="ä»Šæ—¥å…³é”®è¯", lines=5,
                                                               info="ç‚¹å‡»ã€ç”Ÿæˆä»Šæ—¥å…³é”®è¯ã€‘ï¼Œçœ‹çœ‹AIæ€»ç»“çš„ä½ è¿˜æ»¡æ„å—ï¼Ÿ\nä½ ä¹Ÿå¯ä»¥è¾“å…¥æƒ³è¦å‡ºé¢˜çš„çŸ¥è¯†å…³é”®è¯ã€‚\nç‚¹å‡»ã€ç”Ÿæˆæ–°é¢˜ç›®ã€‘çœ‹çœ‹AIç»™ä½ å‡ºäº†ä»€ä¹ˆé¢˜å§ï¼")
                                    generate_keywords_button = gr.Button("ç”Ÿæˆå…³é”®è¯", variant='primary')
                                    generate_problem_button = gr.Button("ç”Ÿæˆæ–°é¢˜ç›®", variant='primary')

                            with gr.Column():
                                with gr.Tab("ç­”é¢˜åŒº"):
                                    with gr.Row():
                                        subject = gr.Textbox(label="ç§‘ç›®", value=problemset.subject)
                                        difficulty = gr.Textbox(label="éš¾åº¦", value=problemset.difficulty)
                                    question_markdown = gr.Markdown("## " + problemset.question)
                                    options = ["A." + problemset.choices[0], "B." + problemset.choices[1],
                                               "C." + problemset.choices[2], "D." + problemset.choices[3]]
                                    choices_radio = gr.Radio(options, label="é€‰æ‹©ä½ è®¤ä¸ºæ­£ç¡®çš„ä¸€é¡¹")

                                    answer_submit_button = gr.Button("âœï¸ é€‰å¥½å•¦ï¼Œæäº¤ç­”æ¡ˆâœï¸ ", variant='primary')
                                    answer_result = gr.Textbox(label="ç­”é¢˜ç»“æœ")
                                    save_problem_button = gr.Button("ä¿å­˜æœ¬é¢˜è®°å½•")
                                    with gr.Accordion("æŸ¥çœ‹è§£æ", open=False):
                                        analysis = gr.Textbox(label="è§£æ", lines=3, interactive=False,
                                                              value=problemset.analysis)
                        with gr.Row():
                            with gr.Tab("ç­”é¢˜è®°å½•"):
                                with gr.Row():
                                    with gr.Column(scale=1):
                                        save_file = gr.File(label="ç”Ÿæˆçš„ç­”é¢˜è®°å½•æ–‡ä»¶(xslx)")
                                    with gr.Column(scale=2):
                                        questions = gr.Dataframe(headers=problemset.ques_header, interactive=False,
                                                                 row_count=3)
                                        save_record_button = gr.Button("ç”Ÿæˆç­”é¢˜è®°å½•", variant='primary')
                                        clear_record_button = gr.Button("æ¸…ç©ºç­”é¢˜è®°å½•")
                    with gr.Row():
                        return_welcome_button = gr.Button(value="â†©ï¸è¿”å›é¦–é¡µ")
    introduce_tab = gr.Tab('ä½œå“ä»‹ç»')
    with introduce_tab:
        gr.HTML(format_introduce_html())
        with gr.Row():
            return_welcome_button2 = gr.Button(value="â†©ï¸è¿”å›é¦–é¡µ", )

    # å­˜å‚¨æ‰€æœ‰éœ€è¦æ¸…ç©ºçš„Textboxç»„ä»¶å¼•ç”¨
    all_textboxes = [
        text_story_title, text_story_content,
        text_more_story_title1, text_more_story_title2, text_more_story_title3,
        keywords_text, subject, difficulty,
        ques_text_1, ques_text_2, ques_text_3, user_chat_input,
    ]

    start_button.click(main_ui, inputs=[state, topic], outputs=[welcome_tab, main_tab])
    return_welcome_button.click(welcome_ui, inputs=[state, topic], outputs=[welcome_tab, main_tab])
    return_welcome_button2.click(welcome_ui, inputs=[state, topic], outputs=[welcome_tab, main_tab])
    story_submit.click(story_submit_click, inputs=[text_story_title, topic], outputs=[text_story_content])
    # print(global_topic_value.value)
    # update_global_topic(global_topic_value)
    story_more.click(story_more_click, inputs=[topic],
                     outputs=[text_more_story_title1, text_more_story_title2,
                              text_more_story_title3])
    audio_submit.click(tts_speech_synthesis, inputs=[text_story_content],
                       outputs=[audio_story_content])
    image_submit.click(generate_images, inputs=[text_story_content],
                       outputs=[image0, image1, image2, image3])
    choose_story1.click(transfer_text, inputs=[text_more_story_title1], outputs=[text_story_title])
    choose_story2.click(transfer_text, inputs=[text_more_story_title2], outputs=[text_story_title])
    choose_story3.click(transfer_text, inputs=[text_more_story_title3], outputs=[text_story_title])
    generate_keywords_button.click(generate_keywords_click, inputs=[state], outputs=[keywords_text])
    generate_problem_button.click(generate_problem_click, inputs=[keywords_text, state],
                                  outputs=[question_markdown, choices_radio, subject, difficulty,
                                           analysis])
    answer_submit_button.click(answer_submit_click, inputs=[choices_radio, state],
                               outputs=[answer_result])
    save_problem_button.click(save_problem_click, inputs=[state], outputs=[questions])
    save_record_button.click(save_record_click, outputs=[save_file])
    clear_record_button.click(clear_record_click, outputs=[questions])
    ques_gen_button.click(ques_gen_click, inputs=[state, topic],
                          outputs=[ques_text_1, ques_text_2, ques_text_3])
    ques_button_1.click(ques_button_click, inputs=[ques_text_1], outputs=[user_chat_input])
    ques_button_2.click(ques_button_click, inputs=[ques_text_2], outputs=[user_chat_input])
    ques_button_3.click(ques_button_click, inputs=[ques_text_3], outputs=[user_chat_input])
    send_button.click(send_button_click, inputs=[user_chat_input, state, user_chatbot],
                      outputs=[user_chatbot, user_chat_input])
    answer_audio_gen_button.click(tts_speech_synthesis1, inputs=[user_chatbot],
                                  outputs=[answer_audio])
    answer_image_gen_button.click(generate_images1, inputs=[user_chatbot,state],
                                  outputs=[answer_image0, answer_image1])
    answer_video_gen_button.click(answer_video_gen_click, inputs=[state], outputs=[answer_video])
demo.launch(server_name='127.0.0.1', server_port=7861)
